{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nexus Domain Meta Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import ast\n",
    "import numpy as np\n",
    "\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "from sqlalchemy import create_engine, text\n",
    "from sqlalchemy.orm import sessionmaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DOMAINS = ['blockchain', 'chatbot', 'innovation', 'intelligent+enterprise', 'cloud', 'crm', ]\n",
    "DB_CONNECT_STRING = 'mysql+pymysql://root:Initial0@10.58.78.253:3306/nexus?charset=utf8mb4'\n",
    "\n",
    "engine = create_engine(DB_CONNECT_STRING, max_overflow=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spider_fetch_count(domain):\n",
    "    request_urls = []\n",
    "    results = engine.execute(f\"select topics from spider_jam_search where body <> '[]' and keyword = '{domain}'\")\n",
    "    # print('total search pages', results.rowcount)\n",
    "\n",
    "    for r in results:\n",
    "        request_urls.extend(ast.literal_eval(r.topics))\n",
    "\n",
    "    set_request_urls = set()\n",
    "    for r in request_urls:\n",
    "        set_request_urls.add(r.replace('http://jam4.sapjam.com', '').replace('https://jam4.sapjam.com', ''))\n",
    "\n",
    "    # 全部不重复的URL set\n",
    "    print('distinct post (processed) url', len(set_request_urls), '/', len(request_urls))\n",
    "\n",
    "    # 获取未处理的urls\n",
    "    set_exist_urls_spider = set()\n",
    "    results = engine.execute(f\"select distinct baseurl from spider_jam_post where keyword = '{domain}'\")\n",
    "\n",
    "    for r in results:\n",
    "        set_exist_urls_spider.add(r.baseurl.replace('http://jam4.sapjam.com', '').replace('https://jam4.sapjam.com', ''))\n",
    "\n",
    "    # 获取已处理的urls\n",
    "    set_exist_urls_processed = set()\n",
    "    results = engine.execute(f\"select distinct url from jam_post where keyword = '{domain}'\")\n",
    "\n",
    "    for r in results:\n",
    "        set_exist_urls_processed.add(r.url.replace('http://jam4.sapjam.com', '').replace('https://jam4.sapjam.com', ''))\n",
    "\n",
    "    request_urls = list(set_request_urls - set_exist_urls_spider - set_exist_urls_processed)\n",
    "\n",
    "    # 最终需要爬取的URL\n",
    "    print('exist(spider) + exist(processed) + require', len(set_exist_urls_spider), len(set_exist_urls_processed), len(request_urls))\n",
    "    \n",
    "    return len(request_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_meta_data(domain):\n",
    "    meta_data = dict()\n",
    "    print(domain)\n",
    "    \n",
    "    sql = \"select count(*) from spider_jam_search where keyword = :domain\"\n",
    "    spider_search_pages = engine.execute(text(sql), domain=domain).fetchall()[0][0]\n",
    "    meta_data['spider_search_pages'] = int(spider_search_pages)\n",
    "    print('spider_search_pages:', spider_search_pages)\n",
    "  \n",
    "    sql = \"select count(*) from spider_jam_post where keyword = :domain\"\n",
    "    spider_posts = engine.execute(text(sql), domain=domain).fetchall()[0][0]\n",
    "    spider_fetch_posts = get_spider_fetch_count(domain)\n",
    "    meta_data['spider_posts'] = int(spider_posts)\n",
    "    meta_data['spider_fetch_posts'] = int(spider_fetch_posts)\n",
    "    print('spider_posts:', spider_posts, 'spider_fetch_posts', spider_fetch_posts)\n",
    "    \n",
    "    sql = \"select count(distinct url) from jam_post where keyword = :domain\"\n",
    "    jam_posts = engine.execute(text(sql), domain=domain).fetchall()[0][0]\n",
    "    meta_data['jam_posts'] = int(jam_posts)\n",
    "    print('jam_posts:', jam_posts)\n",
    "\n",
    "    sql = \"select recency from jam_post where keyword = :domain and recency is not null order by recency desc limit 1\"\n",
    "    result = engine.execute(text(sql), domain=domain).fetchall()\n",
    "    if len(result) > 0:\n",
    "        recency = result[0][0]\n",
    "        if recency:\n",
    "            meta_data['jam_posts_end_date'] = datetime.datetime.fromtimestamp(int(recency)/1000).strftime('%Y-%m-%d')\n",
    "        else:\n",
    "            meta_data['jam_posts_end_date'] = None\n",
    "    else:\n",
    "        meta_data['jam_posts_end_date'] = None\n",
    "    print('jam_posts_end_date:', meta_data['jam_posts_end_date'])\n",
    "    \n",
    "    sql = \"select recency from jam_post where keyword = :domain and recency is not null order by recency limit 1\"\n",
    "    result = engine.execute(text(sql), domain=domain).fetchall()\n",
    "    if len(result) > 0:\n",
    "        recency = result[0][0]\n",
    "        if recency:\n",
    "            meta_data['jam_posts_start_date'] = datetime.datetime.fromtimestamp(int(recency)/1000).strftime('%Y-%m-%d')\n",
    "        else:\n",
    "            meta_data['jam_posts_start_date'] = None\n",
    "    else:\n",
    "        meta_data['jam_posts_start_date'] = None\n",
    "    print('jam_posts_start_date:', meta_data['jam_posts_start_date'])\n",
    "    \n",
    "    sql = \"select count(distinct username) from jam_people_from_post where keyword = :domain and roletype = 'creator'\"\n",
    "    people_creators = engine.execute(text(sql), domain=domain).fetchall()[0][0]\n",
    "    meta_data['people_creators'] = people_creators\n",
    "    print('people_creators:', people_creators)\n",
    "    \n",
    "    sql = \"select count(distinct username) from jam_people_from_post where keyword = :domain and roletype = 'participator'\"\n",
    "    people_participators = engine.execute(text(sql), domain=domain).fetchall()[0][0]\n",
    "    meta_data['people_participators'] = people_participators\n",
    "    print('people_participators:', people_participators)\n",
    "    \n",
    "    print('\\n')\n",
    "    \n",
    "    return meta_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blockchain\n",
      "spider_search_pages: 1149\n",
      "distinct post (processed) url 20932 / 22979\n",
      "exist(spider) + exist(processed) + require 20892 19823 22\n",
      "spider_posts: 24445 spider_fetch_posts 22\n",
      "jam_posts: 19823\n",
      "jam_posts_end_date: 2018-07-13\n",
      "jam_posts_start_date: 2014-03-10\n",
      "people_creators: 4621\n",
      "people_participators: 5238\n",
      "\n",
      "\n",
      "chatbot\n",
      "spider_search_pages: 237\n",
      "distinct post (processed) url 4476 / 4740\n",
      "exist(spider) + exist(processed) + require 4470 4175 4\n",
      "spider_posts: 4470 spider_fetch_posts 4\n",
      "jam_posts: 4175\n",
      "jam_posts_end_date: 2018-07-12\n",
      "jam_posts_start_date: 2013-04-25\n",
      "people_creators: 1769\n",
      "people_participators: 1999\n",
      "\n",
      "\n",
      "innovation\n",
      "spider_search_pages: 11488\n",
      "distinct post (processed) url 152748 / 229760\n",
      "exist(spider) + exist(processed) + require 119931 0 32817\n",
      "spider_posts: 119931 spider_fetch_posts 32817\n",
      "jam_posts: 0\n",
      "jam_posts_end_date: None\n",
      "jam_posts_start_date: None\n",
      "people_creators: 0\n",
      "people_participators: 0\n",
      "\n",
      "\n",
      "intelligent+enterprise\n",
      "spider_search_pages: 420\n",
      "distinct post (processed) url 6885 / 8383\n",
      "exist(spider) + exist(processed) + require 7997 7577 5\n",
      "spider_posts: 7997 spider_fetch_posts 5\n",
      "jam_posts: 7577\n",
      "jam_posts_end_date: 2018-07-26\n",
      "jam_posts_start_date: 2013-02-08\n",
      "people_creators: 1951\n",
      "people_participators: 2215\n",
      "\n",
      "\n",
      "cloud\n",
      "spider_search_pages: 22247\n",
      "distinct post (processed) url 286588 / 444823\n",
      "exist(spider) + exist(processed) + require 0 0 286588\n",
      "spider_posts: 0 spider_fetch_posts 286588\n",
      "jam_posts: 0\n",
      "jam_posts_end_date: None\n",
      "jam_posts_start_date: None\n",
      "people_creators: 0\n",
      "people_participators: 0\n",
      "\n",
      "\n",
      "crm\n",
      "spider_search_pages: 8954\n",
      "distinct post (processed) url 115917 / 179080\n",
      "exist(spider) + exist(processed) + require 115843 0 74\n",
      "spider_posts: 115843 spider_fetch_posts 74\n",
      "jam_posts: 0\n",
      "jam_posts_end_date: None\n",
      "jam_posts_start_date: None\n",
      "people_creators: 0\n",
      "people_participators: 0\n",
      "\n",
      "\n",
      "[{\"blockchain\": {\"spider_search_pages\": 1149, \"spider_posts\": 24445, \"spider_fetch_posts\": 22, \"jam_posts\": 19823, \"jam_posts_end_date\": \"2018-07-13\", \"jam_posts_start_date\": \"2014-03-10\", \"people_creators\": 4621, \"people_participators\": 5238}}, {\"chatbot\": {\"spider_search_pages\": 237, \"spider_posts\": 4470, \"spider_fetch_posts\": 4, \"jam_posts\": 4175, \"jam_posts_end_date\": \"2018-07-12\", \"jam_posts_start_date\": \"2013-04-25\", \"people_creators\": 1769, \"people_participators\": 1999}}, {\"innovation\": {\"spider_search_pages\": 11488, \"spider_posts\": 119931, \"spider_fetch_posts\": 32817, \"jam_posts\": 0, \"jam_posts_end_date\": null, \"jam_posts_start_date\": null, \"people_creators\": 0, \"people_participators\": 0}}, {\"intelligent+enterprise\": {\"spider_search_pages\": 420, \"spider_posts\": 7997, \"spider_fetch_posts\": 5, \"jam_posts\": 7577, \"jam_posts_end_date\": \"2018-07-26\", \"jam_posts_start_date\": \"2013-02-08\", \"people_creators\": 1951, \"people_participators\": 2215}}, {\"cloud\": {\"spider_search_pages\": 22247, \"spider_posts\": 0, \"spider_fetch_posts\": 286588, \"jam_posts\": 0, \"jam_posts_end_date\": null, \"jam_posts_start_date\": null, \"people_creators\": 0, \"people_participators\": 0}}, {\"crm\": {\"spider_search_pages\": 8954, \"spider_posts\": 115843, \"spider_fetch_posts\": 74, \"jam_posts\": 0, \"jam_posts_end_date\": null, \"jam_posts_start_date\": null, \"people_creators\": 0, \"people_participators\": 0}}]\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for d in DOMAINS:\n",
    "    results.append({d: get_meta_data(d)})\n",
    "    \n",
    "print(json.dumps(results))\n",
    "\n",
    "with open(f\"./output/domain-meta-data.json\",'w',encoding='utf-8') as json_file:\n",
    "    json.dump(results, json_file, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
